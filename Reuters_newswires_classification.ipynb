{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters Newswire: Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the size of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8982\n",
      "Test set size: 2246\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size: %s\" %len(train_data))\n",
    "print(\"Test set size: %s\" %len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the IDMB reviews, each sample is a list of word indices that we can decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]),\n",
       "       list([1, 56, 141, 5618, 1607, 149, 8, 16, 33, 223, 231, 336, 7, 37, 38, 459, 1017, 97, 916, 1077, 22, 1271, 19, 89, 16, 8, 4, 455, 33, 45, 30, 2265, 9376, 6, 255, 231, 1025, 4, 49, 8, 43, 10, 447, 5, 329, 1118, 307, 5, 25, 280, 189, 55, 2129, 7, 4, 214, 212, 17, 12])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'??? lt international thomson organisation ltd said it will report financial results in u s funds rather than sterling beginning from jan 1 1987 it said the change will not be applied retroactively to prior financial periods the company said as a result of recent investments most of its assets now are located in the united states reuter 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# note indices are offset by 3 as first 3 are reserved for padding, start of sequence and unknown\n",
    "# if word is not in index, then show '???'\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '???') for i in train_data[11]])\n",
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the relative occurrence of the various topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   55],\n",
       "       [   1,  432],\n",
       "       [   2,   74],\n",
       "       [   3, 3159],\n",
       "       [   4, 1949],\n",
       "       [   5,   17],\n",
       "       [   6,   48],\n",
       "       [   7,   16],\n",
       "       [   8,  139],\n",
       "       [   9,  101],\n",
       "       [  10,  124],\n",
       "       [  11,  390],\n",
       "       [  12,   49],\n",
       "       [  13,  172],\n",
       "       [  14,   26],\n",
       "       [  15,   20],\n",
       "       [  16,  444],\n",
       "       [  17,   39],\n",
       "       [  18,   66],\n",
       "       [  19,  549],\n",
       "       [  20,  269],\n",
       "       [  21,  100],\n",
       "       [  22,   15],\n",
       "       [  23,   41],\n",
       "       [  24,   62],\n",
       "       [  25,   92],\n",
       "       [  26,   24],\n",
       "       [  27,   15],\n",
       "       [  28,   48],\n",
       "       [  29,   19],\n",
       "       [  30,   45],\n",
       "       [  31,   39],\n",
       "       [  32,   32],\n",
       "       [  33,   11],\n",
       "       [  34,   50],\n",
       "       [  35,   10],\n",
       "       [  36,   49],\n",
       "       [  37,   19],\n",
       "       [  38,   19],\n",
       "       [  39,   24],\n",
       "       [  40,   36],\n",
       "       [  41,   30],\n",
       "       [  42,   13],\n",
       "       [  43,   21],\n",
       "       [  44,   12],\n",
       "       [  45,   18]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.bincount(train_labels)\n",
    "ii = np.nonzero(y)[0]\n",
    "np.vstack((ii,y[ii])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 46 topics with topic 35 being the rarest with only 10 occurrences.\n",
    "\n",
    "## 1.1. Data Manipulation\n",
    "Given that each list has differing lengths, we can prepare the data in two ways:\n",
    "    - pad lists so they are the same length\n",
    "    - one-hot encode each sequence into a 10,000-D vector\n",
    "We choose the latter approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to vectorize the labels we cam:\n",
    "- cast the label as an integer\n",
    "- one-hot encode each labels into a 46-D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "# Alternatively, we could use keras to do this\n",
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining Network Architecture\n",
    "As we have a large number of output classes (i.e. 46), we need a relatively large number of hidden units in each layer. This ensures that we don't have an information bottleneck. We define a densely-connected network with the final layer having a softmax output. This ensures the network outputs a probability distribution over the 46 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to minimize categorical crossentropy (i.e. minimize distance between ground-truth probability distributions of the labels and the probability distribution predicted by the neural network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training the model\n",
    "We set aside 1,000 of the 8,982 training examples for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 2.6690 - accuracy: 0.5160 - val_loss: 1.7068 - val_accuracy: 0.6310\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 1.3890 - accuracy: 0.7121 - val_loss: 1.2777 - val_accuracy: 0.7200\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 1.0211 - accuracy: 0.7844 - val_loss: 1.1077 - val_accuracy: 0.7610\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.7973 - accuracy: 0.8296 - val_loss: 1.0046 - val_accuracy: 0.7770\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.6375 - accuracy: 0.8624 - val_loss: 0.9583 - val_accuracy: 0.7950\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.5096 - accuracy: 0.8916 - val_loss: 0.9225 - val_accuracy: 0.8080\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.4147 - accuracy: 0.9112 - val_loss: 0.8885 - val_accuracy: 0.8150\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.3366 - accuracy: 0.9256 - val_loss: 0.8818 - val_accuracy: 0.8090\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.2820 - accuracy: 0.9379 - val_loss: 0.8957 - val_accuracy: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.2377 - accuracy: 0.9454 - val_loss: 0.9294 - val_accuracy: 0.8010\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.2022 - accuracy: 0.9513 - val_loss: 0.9310 - val_accuracy: 0.8110\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.1811 - accuracy: 0.9513 - val_loss: 0.9333 - val_accuracy: 0.8110\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.1605 - accuracy: 0.9544 - val_loss: 0.9641 - val_accuracy: 0.8030\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 0.1521 - accuracy: 0.9546 - val_loss: 1.0274 - val_accuracy: 0.7940\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.1386 - accuracy: 0.9539 - val_loss: 1.0138 - val_accuracy: 0.8080\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.1316 - accuracy: 0.9553 - val_loss: 1.0152 - val_accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.1257 - accuracy: 0.9550 - val_loss: 1.0100 - val_accuracy: 0.8110\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1167 - accuracy: 0.9569 - val_loss: 1.0096 - val_accuracy: 0.8010\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.1130 - accuracy: 0.9580 - val_loss: 1.0409 - val_accuracy: 0.8050\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.1108 - accuracy: 0.9595 - val_loss: 1.0927 - val_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can monitor how the accuracy and the categorical cross-entropy vary with epochs over both the training and the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe338013150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZgU1dn38e/NIoiMgCyiIAyojwrIMk4QAgoujy/uS4yKuGsIGrcY30ceNYmakBg1iqivkURNIhPRaFxi3COJa1BAVhFBHXQEEZBVQB243z9OzdAM3TM9zFR3z/Tvc111dXfVqaq7a3rqrjqn6pS5OyIikr+aZDsAERHJLiUCEZE8p0QgIpLnlAhERPKcEoGISJ5TIhARyXNKBFKvzKypma03s271WTabzGwfM6v366zN7EgzK034vMDMDkmn7A6s6w9mdu2Ozl/Ncn9pZn+s7+VKZjXLdgCSXWa2PuFjK+BrYHP0+YfuXlKb5bn7ZqB1fZfNB+6+X30sx8wuAs5y9+EJy76oPpYtjZMSQZ5z98odcXTEeZG7v5yqvJk1c/fyTMQmIpmhqiGpVnTq/4iZPWxm64CzzGywmf3HzFab2VIzm2BmzaPyzczMzaww+jwpmv6cma0zs7fMrEdty0bTjzazD8xsjZndZWZvmNl5KeJOJ8YfmtkiM1tlZhMS5m1qZneY2Uoz+xAYUc32ud7MJlcZd4+Z3R69v8jM5kff58PoaD3VssrMbHj0vpWZPRTFNg84KMl6P4qWO8/MTojGHwjcDRwSVbutSNi2NyTMPyb67ivN7Ekz2yOdbVMTMzspime1mb1iZvslTLvWzJaY2Vozez/huw4ysxnR+GVmdmu665N64u4aNODuAKXAkVXG/RL4BjiecOCwM/Ad4GDCGWVP4APg0qh8M8CBwujzJGAFUAw0Bx4BJu1A2U7AOuDEaNpVwLfAeSm+SzoxPgW0AQqBLyu+O3ApMA/oCrQHXg3/KknX0xNYD+ySsOwvgOLo8/FRGQMOBzYCfaNpRwKlCcsqA4ZH728D/gW0A7oD71UpexqwR/Q3OTOKYfdo2kXAv6rEOQm4IXp/VBRjf6Al8P+AV9LZNkm+/y+BP0bvD4jiODz6G10bbffmQG9gMdA5KtsD6Bm9fwcYGb0vAA7O9v9Cvg06I5B0vO7uf3f3Le6+0d3fcfep7l7u7h8BE4Fh1cz/mLtPc/dvgRLCDqi2ZY8DZrr7U9G0OwhJI6k0Y/y1u69x91LCTrdiXacBd7h7mbuvBG6uZj0fAXMJCQrgv4HV7j4tmv53d//Ig1eAfwJJG4SrOA34pbuvcvfFhKP8xPU+6u5Lo7/JXwhJvDiN5QKMAv7g7jPdfRMwFhhmZl0TyqTaNtU5A3ja3V+J/kY3A7sSEnI5Ien0jqoXP462HYSEvq+ZtXf3de4+Nc3vIfVEiUDS8WniBzPb38z+YWafm9la4CagQzXzf57wfgPVNxCnKrtnYhzu7oQj6KTSjDGtdRGOZKvzF2Bk9P5MQgKriOM4M5tqZl+a2WrC0Xh126rCHtXFYGbnmdmsqApmNbB/msuF8P0ql+fua4FVQJeEMrX5m6Va7hbC36iLuy8AfkL4O3wRVTV2joqeD/QCFpjZ22Z2TJrfQ+qJEoGko+qlk/cRjoL3cfddgZ8Rqj7itJRQVQOAmRnb7riqqkuMS4G9Ej7XdHnrI8CR0RH1iYTEgJntDDwG/JpQbdMWeDHNOD5PFYOZ9QTuBS4G2kfLfT9huTVd6rqEUN1UsbwCQhXUZ2nEVZvlNiH8zT4DcPdJ7j6EUC3UlLBdcPcF7n4Gofrvt8DjZtayjrFILSgRyI4oANYAX5nZAcAPM7DOZ4AiMzvezJoBVwAdY4rxUeBKM+tiZu2Ba6or7O7LgNeBB4EF7r4wmtQC2AlYDmw2s+OAI2oRw7Vm1tbCfRaXJkxrTdjZLyfkxIsIZwQVlgFdKxrHk3gYuNDM+ppZC8IO+TV3T3mGVYuYTzCz4dG6/y+hXWeqmR1gZodF69sYDZsJX+BsM+sQnUGsib7bljrGIrWgRCA74ifAuYR/8vsIR8Sxina2pwO3AyuBvYF3Cfc91HeM9xLq8ucQGjIfS2OevxAaf/+SEPNq4MfAE4QG11MJCS0dPyecmZQCzwF/TljubGAC8HZUZn8gsV79JWAhsMzMEqt4KuZ/nlBF80Q0fzdCu0GduPs8wja/l5CkRgAnRO0FLYBbCO06nxPOQK6PZj0GmG/hqrTbgNPd/Zu6xiPps1DVKtKwmFlTQlXEqe7+WrbjEWnIdEYgDYaZjTCzNlH1wk8JV6K8neWwRBo8JQJpSIYCHxGqF0YAJ7l7qqohEUmTqoZERPKczghERPJcg+t0rkOHDl5YWJjtMEREGpTp06evcPekl1w3uERQWFjItGnTsh2GiEiDYmYp75BX1ZCISJ5TIhARyXNKBCIiea7BtRGISGZ9++23lJWVsWnTpmyHImlo2bIlXbt2pXnzVF1NbU+JQESqVVZWRkFBAYWFhYROXyVXuTsrV66krKyMHj161DxDJC+qhkpKoLAQmjQJryW1ehy7SH7btGkT7du3VxJoAMyM9u3b1/rsrdGfEZSUwOjRsGFD+Lx4cfgMMKrO/S2K5AclgYZjR/5Wjf6M4LrrtiaBChs2hPEiIpIHieCTT2o3XkRyy8qVK+nfvz/9+/enc+fOdOnSpfLzN9+k99iC888/nwULFlRb5p577qGknuqNhw4dysyZM+tlWZnQ6KuGunUL1UHJxotI/SspCWfcn3wS/s/GjatbNWz79u0rd6o33HADrVu35uqrr96mjLvj7jRpkvzY9sEHH6xxPT/60Y92PMgGrtGfEYwbB61abTuuVaswXkTqV0Wb3OLF4L61TS6OCzQWLVpEnz59GDNmDEVFRSxdupTRo0dTXFxM7969uemmmyrLVhyhl5eX07ZtW8aOHUu/fv0YPHgwX3zxBQDXX38948ePryw/duxYBg4cyH777cebb74JwFdffcX3vvc9+vXrx8iRIykuLq7xyH/SpEkceOCB9OnTh2uvvRaA8vJyzj777MrxEyZMAOCOO+6gV69e9OvXj7POOqvet1kqjT4RjBoFEydC9+5gFl4nTlRDsUgcMt0m995773HhhRfy7rvv0qVLF26++WamTZvGrFmzeOmll3jvvfe2m2fNmjUMGzaMWbNmMXjwYB544IGky3Z33n77bW699dbKpHLXXXfRuXNnZs2axdixY3n33Xerja+srIzrr7+eKVOm8O677/LGG2/wzDPPMH36dFasWMGcOXOYO3cu55xzDgC33HILM2fOZNasWdx999113Drpa/SJAMJOv7QUtmwJr0oCIvHIdJvc3nvvzXe+853Kzw8//DBFRUUUFRUxf/78pIlg55135uijjwbgoIMOorS0NOmyTznllO3KvP7665xxxhkA9OvXj969e1cb39SpUzn88MPp0KEDzZs358wzz+TVV19ln332YcGCBVxxxRW88MILtGnTBoDevXtz1llnUVJSUqsbwuoqLxKBiGRGqra3uNrkdtlll8r3Cxcu5M477+SVV15h9uzZjBgxIun19DvttFPl+6ZNm1JeXp502S1atNiuTG0f5JWqfPv27Zk9ezZDhw5lwoQJ/PCHPwTghRdeYMyYMbz99tsUFxezefPmWq1vRykRiEi9yWab3Nq1aykoKGDXXXdl6dKlvPDCC/W+jqFDh/Loo48CMGfOnKRnHIkGDRrElClTWLlyJeXl5UyePJlhw4axfPly3J3vf//73HjjjcyYMYPNmzdTVlbG4Ycfzq233sry5cvZULWeLSaN/qohEcmcimrX+rxqKF1FRUX06tWLPn360LNnT4YMGVLv67jssss455xz6Nu3L0VFRfTp06eyWieZrl27ctNNNzF8+HDcneOPP55jjz2WGTNmcOGFF+LumBm/+c1vKC8v58wzz2TdunVs2bKFa665hoKCgnr/Dsk0uGcWFxcXux5MI5I58+fP54ADDsh2GDmhvLyc8vJyWrZsycKFCznqqKNYuHAhzZrl1jF1sr+ZmU139+Jk5XMrehGRHLZ+/XqOOOIIysvLcXfuu+++nEsCOyK2b2BmewF/BjoDW4CJ7n5nlTLDgaeAj6NRf3P3mxARyUFt27Zl+vTp2Q6j3sWZysqBn7j7DDMrAKab2UvuXrV15TV3Py7GOEREpBqxXTXk7kvdfUb0fh0wH+gS1/pERGTHZOTyUTMrBAYAU5NMHmxms8zsOTNLeneGmY02s2lmNm358uUxRioikn9iTwRm1hp4HLjS3ddWmTwD6O7u/YC7gCeTLcPdJ7p7sbsXd+zYMd6ARUTyTKyJwMyaE5JAibv/rep0d1/r7uuj988Czc2sQ5wxiUjDMnz48O1uDhs/fjyXXHJJtfO1bt0agCVLlnDqqaemXHZNl6OPHz9+mxu7jjnmGFavXp1O6NW64YYbuO222+q8nPoQWyKw8Jic+4H57n57ijKdo3KY2cAonpVxxSQiDc/IkSOZPHnyNuMmT57MyJEj05p/zz335LHHHtvh9VdNBM8++yxt27bd4eXlojjPCIYAZwOHm9nMaDjGzMaY2ZiozKnAXDObBUwAzvCGdoebiMTq1FNP5ZlnnuHrr78GoLS0lCVLljB06NDK6/qLioo48MADeeqpp7abv7S0lD59+gCwceNGzjjjDPr27cvpp5/Oxo0bK8tdfPHFlV1Y//znPwdgwoQJLFmyhMMOO4zDDjsMgMLCQlasWAHA7bffTp8+fejTp09lF9alpaUccMAB/OAHP6B3794cddRR26wnmZkzZzJo0CD69u3LySefzKpVqyrX36tXL/r27VvZ2d2///3vygfzDBgwgHXr1u3wtq0Q2+Wj7v46UO3DM939biBzfa2KSJ1ceSXU94O3+veHaB+aVPv27Rk4cCDPP/88J554IpMnT+b000/HzGjZsiVPPPEEu+66KytWrGDQoEGccMIJKZ/be++999KqVStmz57N7NmzKSoqqpw2btw4dtttNzZv3swRRxzB7Nmzufzyy7n99tuZMmUKHTpsW2s9ffp0HnzwQaZOnYq7c/DBBzNs2DDatWvHwoULefjhh/n973/PaaedxuOPP17t8wXOOecc7rrrLoYNG8bPfvYzbrzxRsaPH8/NN9/Mxx9/TIsWLSqro2677TbuuecehgwZwvr162nZsmUttnZy6nRORHJeYvVQYrWQu3PttdfSt29fjjzySD777DOWLVuWcjmvvvpq5Q65b9++9O3bt3Lao48+SlFREQMGDGDevHk1dij3+uuvc/LJJ7PLLrvQunVrTjnlFF577TUAevToQf/+/YHqu7qG8HyE1atXM2zYMADOPfdcXn311coYR40axaRJkyrvYB4yZAhXXXUVEyZMYPXq1fVyZ3PDvzdaRDKmuiP3OJ100klcddVVzJgxg40bN1YeyZeUlLB8+XKmT59O8+bNKSwsTNr1dKJkZwsff/wxt912G++88w7t2rXjvPPOq3E51dViV3RhDaEb65qqhlL5xz/+wauvvsrTTz/NL37xC+bNm8fYsWM59thjefbZZxk0aBAvv/wy+++//w4tv4LOCEQk57Vu3Zrhw4dzwQUXbNNIvGbNGjp16kTz5s2ZMmUKi5M9oDzBoYceWvmA+rlz5zJ79mwgdGG9yy670KZNG5YtW8Zzzz1XOU9BQUHSevhDDz2UJ598kg0bNvDVV1/xxBNPcMghh9T6u7Vp04Z27dpVnk089NBDDBs2jC1btvDpp59y2GGHccstt7B69WrWr1/Phx9+yIEHHsg111xDcXEx77//fq3XWZXOCESkQRg5ciSnnHLKNlcQjRo1iuOPP57i4mL69+9f45HxxRdfzPnnn0/fvn3p378/AwcOBMLTxgYMGEDv3r2368J69OjRHH300eyxxx5MmTKlcnxRURHnnXde5TIuuugiBgwYUG01UCp/+tOfGDNmDBs2bKBnz548+OCDbN68mbPOOos1a9bg7vz4xz+mbdu2/PSnP2XKlCk0bdqUXr16VT5trS7UDbWIVEvdUDc8te2GWlVDIiJ5TolARCTPKRGISI0aWhVyPtuRv5USgYhUq2XLlqxcuVLJoAFwd1auXFnrm8x01ZCIVKtr166UlZWhLuAbhpYtW9K1a9dazaNEICLVat68OT169Mh2GBIjVQ2JiOQ5JQIRkTynRCAikueUCERE8pwSgYhInlMiEBHJc0oEIiJ5TolARCTPKRGIiOQ5JQIRkTynRCAikueUCERE8pwSgYhInlMiEBHJc0oEIiJ5TolARCTPKRGIiOQ5JQIRkTynRCAikudiSwRmtpeZTTGz+WY2z8yuSFLGzGyCmS0ys9lmVhRXPCIiklycD68vB37i7jPMrACYbmYvuft7CWWOBvaNhoOBe6NXERHJkNjOCNx9qbvPiN6vA+YDXaoUOxH4swf/Adqa2R5xxSQiItvLSBuBmRUCA4CpVSZ1AT5N+FzG9skCMxttZtPMbNry5cvjClNEJC/FngjMrDXwOHClu6+tOjnJLL7dCPeJ7l7s7sUdO3aMI0wRkbwVayIws+aEJFDi7n9LUqQM2Cvhc1dgSZwxiYjItuK8asiA+4H57n57imJPA+dEVw8NAta4+9K4YhIRke3FedXQEOBsYI6ZzYzGXQt0A3D33wHPAscAi4ANwPkxxiMiIknElgjc/XWStwEklnHgR3HFICIiNdOdxSIieU6JQEQkzykRiIjkOSUCEZE8p0QgIpLnlAhERPKcEoGISJ5TIhARyXNKBCIieU6JQEQkzykRiIjkOSUCEZE8p0QgIpLnlAhERPKcEoGISJ7Lm0TgDlOnZjsKEZHckzeJ4IEHYNAgeOedbEciIpJb8iYRnHYatGsH48ZlOxIRkdySN4mgoACuuAKeegrmzMl2NCIiuSNvEgHAZZeFhPCrX2U7EhGR3JFXiWC33eCSS+CRR2DBgmxHIyKSG/IqEQBcdRW0bAk335ztSEREckPeJYJOnWD0aJg0CUpLsx2NiEj25V0iALj6ajCDW27JdiQiItmXl4mga1c4/3y4/35YsiTb0YiIZFdeJgKAa66BzZvht7/NdiQiItmVt4mgZ08480z43e9g+fJsRyMikj15mwgA/vd/YeNGGD8+25GIiGRPXieCAw6AU0+Fu++G1auzHY2ISHbElgjM7AEz+8LM5qaYPtzM1pjZzGj4WVyxVOfaa2Ht2pAMRETyUZxnBH8ERtRQ5jV37x8NN8UYS0r9+8Nxx8Edd8D69dmIQEQku2JLBO7+KvBlXMuvT9ddB19+Cffdl+1IREQyL9ttBIPNbJaZPWdmvbMVxKBBcMQRcNttofFYRCSfpJUIzGxvM2sRvR9uZpebWds6rnsG0N3d+wF3AU9Ws/7RZjbNzKYtj+laz+uvh88/Dw+wERHJJ+meETwObDazfYD7gR7AX+qyYndf6+7ro/fPAs3NrEOKshPdvdjdizt27FiX1aY0bBgMGRK6nfjmm1hWISKSk9JNBFvcvRw4GRjv7j8G9qjLis2ss5lZ9H5gFMvKuiyzbvGEtoJPPgkd0omI5It0E8G3ZjYSOBd4JhrXvLoZzOxh4C1gPzMrM7MLzWyMmY2JipwKzDWzWcAE4Ax399p/hfozYgQUFcGvfw3l5dmMREQkc5qlWe58YAwwzt0/NrMeQLXHze4+sobpdwM5dfW+WWgrOOUU+OtfYWS130BEpHFI64zA3d9z98vd/WEzawcUuHujfLTLiSdC797hIfdbtoRxJSVQWAhNmoTXkpJsRigiUr/SOiMws38BJ0TlZwLLzezf7n5VjLFlRZMm4W7jUaPCg+43bAgPstmwIUxfvDh8hlBGRKShs3Sq5c3sXXcfYGYXAXu5+8/NbLa7940/xG0VFxf7tGnTYl1HeXnoh6hNm9Az6SefbF+me3c94UxEGg4zm+7uxcmmpdtY3MzM9gBOY2tjcaPVrBmMHQvTpydPApB6vIhIQ5NuIrgJeAH40N3fMbOewML4wsq+s8+GvfaCFi2ST+/WLbPxiIjEJd3G4r+6e193vzj6/JG7fy/e0LJrp53CU8y+/nr7ZNCqVWhMFhFpDNLtYqKrmT0RdSu9zMweN7OucQeXbRdcALvvDvvuG9oEzMLrxIlqKBaRxiPdqqEHgaeBPYEuwN+jcY3azjvD1VfD3LnwyCPhctLSUiUBEWlc0k0EHd39QXcvj4Y/AvF0+pNjxoyB3XZTVZCINF7pJoIVZnaWmTWNhrPIYr9AmdS6NVx5Jfz97zBzZrajERGpf+kmggsIl45+Diwl9BN0flxB5ZrLLoNdd4Vf/SrbkYiI1L90rxr6xN1PcPeO7t7J3U8CTok5tpzRti1ceik89hg8/HC2oxERqV91eUJZo+teojr/8z9wyCFw5pnwv/8LmzdnOyIRkfpRl0Rg9RZFA9CmDbz0Uuhn6Oab4aSTYO3abEclIlJ3dUkEWX12QDbstBP87ndwzz3w3HPhWceLFmU7KhGRuqk2EZjZOjNbm2RYR7inIO+YwSWXhLODZctg4EB4+eVsRyUisuOqTQTuXuDuuyYZCtw93YfaNEqHHQbvvANduoQnm02YANl9vpqIyI6pS9VQ3uvZE958E449Fq64An7wg9A3kYhIQ6JEUEcFBfDEE+ERl/ffD0ccEaqMREQaCiWCetCkCfziFzB5MsyYAd/5Drz7brajEhFJjxJBPTr9dHj99dBWMGQI/PWv2Y5IRKRmSgT1rKgIpk2DAQPgtNPgpz8NvZaKiOQqJYIY7L47vPJKeJ7BL38Jp5wC69ZlOyoRkeSUCGLSogX84Q9w552h59Lvfhc+/jjbUYmIbE+JIEZmcPnl8PzzUFYGxcUwfjxs3JjtyEREtlIiyID//m94+23o2xd+/ONw/8Edd8CGDdmOTERymTvMnw/33hsuRnnooXjWo0SQIfvuC1OmwL//Db16wVVXhYRw++1KCCISVN3xd+4c9heXXAJvvAGrVsWzXvMG1i9CcXGxT5s2Ldth1Nlrr8GNN8I//wmdOoVurseMgV12yXZkIpIp7vD++/Cvf20dvvgiTOvSJXRlM3x4GHr2DNXNO8rMprt7cdJpSgTZ9frrISG8/DJ07BgSwsUXKyGINEaZ3PFXpUSQZSUlcN118Mkn0K0bjBsHo0ZtW+aNN0JCeOmlkBCuvjqcDrZunZ2YRaRuvvwSFiyADz4Ir++/H/7PM7XjryoricDMHgCOA75w9z5JphtwJ3AMsAE4z91n1LTchpYISkrCw2wS2wFatYKJE7dPBhA6sbvxRnjxRejQISSEH/1ICUGyZ82acOXbSy+FI9p27bYd2rbdflzz5tmOOjO+/ho+/DDs6BN3+h98ACtWbC3XrFnY0Q8cmLkdf1XZSgSHAuuBP6dIBMcAlxESwcHAne5+cE3LbWiJoLAQFi/efnz37lBamnq+t96Cm24K/4Dt229NCAUFcUUqslVpabj/5emnQ/VFeXnYwe+8c2iwrOkS6F122T5BtG0LTZuGO+23bAlJpeJ9up+bNQv36Oy00469Nkm4PKZiJ5zqteq4LVvg00+33eGXlm7bc0DnzvBf/wX77bf1db/9oEeP7CfHrFUNmVkh8EyKRHAf8C93fzj6vAAY7u5Lq1tmQ0sETZokf05BxQ+rJlOnhjOE554L/0jDhsHgweEGteLi8I8pUldbtoQOE596Kuz8Z88O4/ffH044IQyDBoUdOYQj4VWrwrB69db3yT5XjFu9OqynSZPw+2/SZOuQzmezkJC++SasP9nrt9/Gv61atUq+s9933/BI21xVXSLI5sNlugCfJnwui8ZtlwjMbDQwGqBbt24ZCa6+dOuW/Iwg3a9x8MHw7LPhPoR77w11jE89FaY1awb9+4fEUDF0757Z001puDZtCl2hPP10OPpfsiTsdIcOhdtug+OPDzu6ZFq0CEe/nTtnNuaabNkSkkGyRPH111sPymp6TTVuzz1D3X5j+x/LZiJItimTnp64+0RgIoQzgjiDqm/jxiVvIxg3rnbLGTgwDBDqHv/zn1B99Oab4TkId90VpnXuvPWMYfBgOOggaNmyfr6LNHzLl8M//hF2/i++CF99FapxRowIR/3HHhuqIhuqJk1CkmrRItuRNCzZTARlwF4Jn7sCS7IUS2wqGoRrumqoNjp0gOOOCwOE0+U5c0JiqEgOTzwRpjVvHnpCHTw4nNr36xdOYZvl9YNGG7+KRswPPtg6zJ0bHq+6ZUs4sj37bDjxxNBwqYOF/JbNNoJjgUvZ2lg8wd0H1rTMhtZGkC3Llm09a3jrrbADqGjg22knOOAA6NMHDjwwvPbpE5JUYzvlbcw2bw6Nl4k7+4ph8eJt26B23z1U8xx2WDjyLyrS3zrfZOuqoYeB4UAHYBnwc6A5gLv/Lrp89G5gBOHy0fPdvcY9vBLBjvn223BEOGdOeK0YPk1opSko2JoUKoYDDwz3NUho7Pz6622vZKnNsHnztkOycdUN33wTrlKp2NkvWrTtM7Jbt97agJk45HojpmSGbiiTlFavhnnztk0Sc+aEm2EqdOq0NTH07h36PjnggIZdl5yKO3z2Wejv5b33wlDxfuXKbEcXqvr23jv5Dn/33XWUL6kpEUituIeqpapnD/PmhcbFCrvvHpJC1aFjx9zfIW3eHI6uK3byia+JDxFq125r4ttvv9CwmnhZY22Hpk3DkPg+3aFZs7DN1b4jO0KJQOpFxQ01FUfKicPatVvL7bZb8gSx557xJ4jy8u2vYf/yy/C6YkW4Cei998Lrpk1b59tjj7Czr9jpV7x26pT7SU0kHbl6H4E0ME2ahPsUuneHo4/eOt49XINeNTk89ti2VUytW8Ouu4YrVFq2DDfDVbyv+jnZtObNw9F6xY696o5+1aqaHwlaWBh28Eceue0Ov23bWDaZSIOgRCB1ZhZusunSJTyEp4J7uG69IjF88EGoWtq0KVzBtGnT1mHVqq3vE6cl68qgZctQZbPbbuG1W7dwWWzF58RpiZ/btg1XTInItpQIJDZmoWqlU6dwrfqOcA9Xy2zaFK6QKShQtxoi9U2JQHKame4UFcPFo7YAAAu3SURBVImbHlUpIpLnlAgagJKS0MjZpEl4LSnJdkQi0pioaijHVX2wzeLF4TPUrb8iEZEKOiPIcdddt23PpRA+X3ddduIRkcZHiSDHffJJ7caLiNSWEkGOS/UAmwb2fB4RyWFKBDlu3LjwIJtEO/JgGxGRVJQIctyoUTBx4tZHUHbvHj6roVhE6ouuGmoARo3Sjl9E4qMzAhGRPKdEICKS55QIRETynBKBiEieUyLIA+qrSESqo6uGGjn1VSQiNdEZQSOnvopEpCZKBI2c+ioSkZooETRy6qtIRGqiRNDIqa8iEamJEkEjp76KRKQmumooD6ivIhGpjs4IRETynBKBiEieUyKQtOjuZJHGK9ZEYGYjzGyBmS0ys7FJpp9nZsvNbGY0XBRnPLJjKu5OXrwY3LfenaxkINI4xJYIzKwpcA9wNNALGGlmvZIUfcTd+0fDH+KKR3ac7k4WadziPCMYCCxy94/c/RtgMnBijOuTmOjuZJHGLc5E0AX4NOFzWTSuqu+Z2Wwze8zM9kq2IDMbbWbTzGza8uXL44hVqqG7k0UatzgTgSUZ51U+/x0odPe+wMvAn5ItyN0nunuxuxd37NixnsOUmujuZJHGLc5EUAYkHuF3BZYkFnD3le7+dfTx98BBMcYjO0h3J4s0bnEmgneAfc2sh5ntBJwBPJ1YwMz2SPh4AjA/xnikDkaNgtJS2LIlvNY2CejyU5HcFVsXE+5ebmaXAi8ATYEH3H2emd0ETHP3p4HLzewEoBz4Ejgvrngke/RwHJHcZu5Vq+1zW3FxsU+bNi3bYUgtFBaGnX9V3buHswsRiZ+ZTXf34mTTdGexxE6Xn4rkNiUCiZ0uPxXJbUoEEjtdfiqS25QIJHb1cfmprjoSiY8eTCMZUZeH4+iqI5F46YxAcp46vROJlxKB5DxddSQSLyUCyXm66kgkXkoEkvPq46ojNTaLpKZEIDmvrlcd6QlrItVTFxPS6KmLCxF1MSF5rj4am1W1JI2ZEoE0enVtbFbVkjR2SgTS6NW1sVn3MUhjp0QgjV5dG5tVtSSNnRKB5IW6PGEtF6qWlEgkTkoEIjXIdtWS2igkbkoEIjXIdtVSfbRR6IxCqqNEIJKGbFYt1TWRqGpKaqJEIBKzulYt1TWR5ELVVF0TiRJRzNy9QQ0HHXSQizQ0kya5d+/ubhZeJ02q3bytWrmH3XAYWrVKfxlm285bMZilN3/37snn7949M/HXdf6KZezo9q+P+XMBMM1T7FezvmOv7aBEIPmoLjuiuu7Is51IlIjqJxEpEYjksbruyLKdSJSI6p6I3KtPBGojEGnk6nrVU7bbOLLd2J7tq74ycWe7EoFIHqjLVU/ZTiRKRHWbPx1KBCJSo2wmEiWius2fllR1Rrk6qI1ARGorm421DaGNQA+mERGJWUlJqNP/5JNwJD9uXO3Oquo6P1T/YBolAhGRPJC1J5SZ2QgzW2Bmi8xsbJLpLczskWj6VDMrjDMeERHZXmyJwMyaAvcARwO9gJFm1qtKsQuBVe6+D3AH8Ju44hERkeTiPCMYCCxy94/c/RtgMnBilTInAn+K3j8GHGFmFmNMIiJSRZyJoAvwacLnsmhc0jLuXg6sAdpXXZCZjTazaWY2bfny5TGFKyKSn+JMBMmO7Ku2TKdTBnef6O7F7l7csWPHeglORESCZjEuuwzYK+FzV2BJijJlZtYMaAN8Wd1Cp0+fvsLMFtdnoPWoA7Ai20FUI9fjg9yPUfHVjeKrm7rE1z3VhDgTwTvAvmbWA/gMOAM4s0qZp4FzgbeAU4FXvIbrWd09Z08JzGxaqsuzckGuxwe5H6PiqxvFVzdxxRdbInD3cjO7FHgBaAo84O7zzOwmwh1uTwP3Aw+Z2SLCmcAZccUjIiLJxXlGgLs/CzxbZdzPEt5vAr4fZwwiIlI9dTpXvyZmO4Aa5Hp8kPsxKr66UXx1E0t8Da6LCRERqV86IxARyXNKBCIieU6JoJbMbC8zm2Jm881snpldkaTMcDNbY2Yzo+FnyZYVY4ylZjYnWvd2XbVaMCHq7G+2mRVlMLb9ErbLTDNba2ZXVimT8e1nZg+Y2RdmNjdh3G5m9pKZLYxe26WY99yozEIzOzeD8d1qZu9Hf8MnzKxtinmr/T3EGN8NZvZZwt/xmBTzVts5ZYzxPZIQW6mZzUwxb6zbL9U+JaO/v1QPKtCQfAD2AIqi9wXAB0CvKmWGA89kMcZSoEM1048BniPc2T0ImJqlOJsCnwPds739gEOBImBuwrhbgLHR+7HAb5LMtxvwUfTaLnrfLkPxHQU0i97/Jll86fweYozvBuDqNH4DHwI9gZ2AWVX/n+KKr8r03wI/y8b2S7VPyeTvT2cEteTuS919RvR+HTCf7ftQynUnAn/24D9AWzPbIwtxHAF86O5Zv1Pc3V9l+7vaEztF/BNwUpJZ/w/wkrt/6e6rgJeAEZmIz91f9NBHF8B/CHfvZ0WK7ZeOdDqnrLPq4os6ujwNeLi+15uOavYpGfv9KRHUQfT8hAHA1CSTB5vZLDN7zsx6ZzSw0F/Ti2Y23cxGJ5meToeAmXAGqf/5srn9Kuzu7ksh/LMCnZKUyZVteQHhLC+Zmn4Pcbo0qrp6IEXVRi5sv0OAZe6+MMX0jG2/KvuUjP3+lAh2kJm1Bh4HrnT3tVUmzyBUd/QD7gKezHB4Q9y9iPAsiB+Z2aFVpqfV2V+czGwn4ATgr0kmZ3v71UYubMvrgHKgJEWRmn4PcbkX2BvoDywlVL9UlfXtB4yk+rOBjGy/GvYpKWdLMq7W20+JYAeYWXPCH6zE3f9Wdbq7r3X39dH7Z4HmZtYhU/G5+5Lo9QvgCcLpd6J0OgSM29HADHdfVnVCtrdfgmUVVWbR6xdJymR1W0aNg8cBozyqNK4qjd9DLNx9mbtvdvctwO9TrDfb268ZcArwSKoymdh+KfYpGfv9KRHUUlSfeD8w391vT1Gmc1QOMxtI2M4rMxTfLmZWUPGe0KA4t0qxp4FzoquHBgFrKk5BMyjlUVg2t18VFZ0iEr0+laTMC8BRZtYuqvo4KhoXOzMbAVwDnODuG1KUSef3EFd8ie1OJ6dYb2XnlNFZ4hmE7Z4pRwLvu3tZsomZ2H7V7FMy9/uLqyW8sQ7AUMKp12xgZjQcA4wBxkRlLgXmEa6A+A/w3QzG1zNa76wohuui8YnxGeExoh8Cc4DiDG/DVoQde5uEcVndfoSktBT4lnCUdSHhIUn/BBZGr7tFZYuBPyTMewGwKBrOz2B8iwj1wxW/w99FZfcEnq3u95Ch+B6Kfl+zCTu1ParGF30+hnClzIeZjC8a/8eK311C2Yxuv2r2KRn7/amLCRGRPKeqIRGRPKdEICKS55QIRETynBKBiEieUyIQEclzSgQiETPbbNv2jFpvPWGaWWFiz5ciuSTWZxaLNDAb3b1/toMQyTSdEYjUIOqP/jdm9nY07BON725m/4w6VfunmXWLxu9u4fkAs6Lhu9GimprZ76M+5180s52j8peb2XvRciZn6WtKHlMiENlq5ypVQ6cnTFvr7gOBu4Hx0bi7Cd159yV0+DYhGj8B+LeHTvOKCHekAuwL3OPuvYHVwPei8WOBAdFyxsT15URS0Z3FIhEzW+/urZOMLwUOd/ePos7BPnf39ma2gtBtwrfR+KXu3sHMlgNd3f3rhGUUEvqN3zf6fA3Q3N1/aWbPA+sJvaw+6VGHeyKZojMCkfR4ivepyiTzdcL7zWxtozuW0PfTQcD0qEdMkYxRIhBJz+kJr29F798k9JYJMAp4PXr/T+BiADNrama7plqomTUB9nL3KcD/AG2B7c5KROKkIw+RrXa2bR9g/ry7V1xC2sLMphIOnkZG4y4HHjCz/wssB86Pxl8BTDSzCwlH/hcTer5MpikwyczaEHqFvcPdV9fbNxJJg9oIRGoQtREUu/uKbMciEgdVDYmI5DmdEYiI5DmdEYiI5DklAhGRPKdEICKS55QIRETynBKBiEie+/85eP6k5G9WPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loss is minimized after 8 epochs of training. Let us examine how accuracy varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe338130ed0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Test set performance\n",
    "Based on the plots above, the network begins to overfit after 9 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 2.6641 - accuracy: 0.5264 - val_loss: 1.7671 - val_accuracy: 0.6250\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 1.4497 - accuracy: 0.7027 - val_loss: 1.3154 - val_accuracy: 0.7200\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 1.0570 - accuracy: 0.7816 - val_loss: 1.1476 - val_accuracy: 0.7500\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.8270 - accuracy: 0.8240 - val_loss: 1.0484 - val_accuracy: 0.7710\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.6526 - accuracy: 0.8601 - val_loss: 0.9666 - val_accuracy: 0.8040\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.5178 - accuracy: 0.8929 - val_loss: 0.9246 - val_accuracy: 0.8180\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.4151 - accuracy: 0.9163 - val_loss: 0.9061 - val_accuracy: 0.8170\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.3419 - accuracy: 0.9278 - val_loss: 0.9410 - val_accuracy: 0.8010\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.2795 - accuracy: 0.9399 - val_loss: 0.9216 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe337ec3dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 64us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9976062732197192, 0.7871772050857544]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of ~80% is achieved. How does this compare to a purely random classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19056099732858414"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the the random classifier only achieves ~18% accuracy... much less than the 79% achieved by the neural network!\n",
    "\n",
    "# 4. Model Performance with other Factors\n",
    "## 4.1. Encoding of Labels\n",
    "Instead of one-hot encoding, we can instead choose to cast the label as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we should rather use a 'sparse categorical cross-entropy' (instead of 'categorical cross-entropy')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.2636 - accuracy: 0.9411 - val_loss: 0.9309 - val_accuracy: 0.8110\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1947 - accuracy: 0.9514 - val_loss: 1.0019 - val_accuracy: 0.8010\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1810 - accuracy: 0.9518 - val_loss: 0.9654 - val_accuracy: 0.8060\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 0.1655 - accuracy: 0.9526 - val_loss: 0.9875 - val_accuracy: 0.8120\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 0.1490 - accuracy: 0.9536 - val_loss: 1.0048 - val_accuracy: 0.8070\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1349 - accuracy: 0.9558 - val_loss: 1.0135 - val_accuracy: 0.8080\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1291 - accuracy: 0.9577 - val_loss: 1.0387 - val_accuracy: 0.8120\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1241 - accuracy: 0.9577 - val_loss: 1.0906 - val_accuracy: 0.7990\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1196 - accuracy: 0.9585 - val_loss: 1.0561 - val_accuracy: 0.8090\n",
      "2246/2246 [==============================] - 0s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1770084819301154, 0.7925200462341309]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves effectively the same accuracy as the previous one. This is expected as 'sparse_categorial_crossentropy' is mathematically identical to 'categorical_crossentropy'. We are just using a different interface. Let's revert back to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Model Architecture\n",
    "We shall both examine how the performance varies as we change the number of hidden layers and the number of units in each layer.\n",
    "\n",
    "### 4.2.1. Number of Units\n",
    "Let us vary the number of hidden units whilst keeping the number of hidden layers at 2 and the number of epochs to train with based on the optimum validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[# Units: 32, Optimum Epochs: 14, Validation Loss: 0.9408710441589355, Validation Accuracy: 0.8109999895095825]\n",
      "[# Units: 64, Optimum Epochs: 8, Validation Loss: 0.8910752620697021, Validation Accuracy: 0.8209999799728394]\n",
      "[# Units: 128, Optimum Epochs: 6, Validation Loss: 0.854744662284851, Validation Accuracy: 0.8289999961853027]\n"
     ]
    }
   ],
   "source": [
    "nUnits = [32, 64, 128]\n",
    "\n",
    "loss_values = np.zeros(len(nUnits))\n",
    "val_loss_values = np.zeros(len(nUnits))\n",
    "acc_values = np.zeros(len(nUnits))\n",
    "val_acc_values = np.zeros(len(nUnits))\n",
    "for i, n in enumerate(nUnits):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(n, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(n, activation='relu'))\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    h = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, \n",
    "                  validation_data=(x_val, y_val), verbose=0)\n",
    "    h = h.history\n",
    "    \n",
    "    minInd = np.argmin(h['val_loss'])\n",
    "    \n",
    "    loss_values[i] = h['loss'][minInd]\n",
    "    val_loss_values[i] = h['val_loss'][minInd]\n",
    "    acc_values[i] = h['accuracy'][minInd]\n",
    "    val_acc_values[i] = h['val_accuracy'][minInd]\n",
    "    \n",
    "    print(\"[# Units: %s, Optimum Epochs: %s, Validation Loss: %s, Validation Accuracy: %s]\"\n",
    "          %(n, minInd + 1, val_loss_values[i], val_acc_values[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that having 64 hidden units is the optimum for validation loss and accuracy. Let us see what would occur if we kept the first layer at 64 hidden units but compress the second layer to 4 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 68us/step - loss: 3.4185 - accuracy: 0.0034 - val_loss: 3.0791 - val_accuracy: 0.0050\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 62us/step - loss: 2.8499 - accuracy: 0.0764 - val_loss: 2.6618 - val_accuracy: 0.2420\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 73us/step - loss: 2.3598 - accuracy: 0.4127 - val_loss: 2.1749 - val_accuracy: 0.5420\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 72us/step - loss: 1.9223 - accuracy: 0.5482 - val_loss: 1.8936 - val_accuracy: 0.5440\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 73us/step - loss: 1.6872 - accuracy: 0.5763 - val_loss: 1.7469 - val_accuracy: 0.5700\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 73us/step - loss: 1.5344 - accuracy: 0.5950 - val_loss: 1.6491 - val_accuracy: 0.5760\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 73us/step - loss: 1.4204 - accuracy: 0.6096 - val_loss: 1.6186 - val_accuracy: 0.5900\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 1.3242 - accuracy: 0.6248 - val_loss: 1.5295 - val_accuracy: 0.6110\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 1.2386 - accuracy: 0.6383 - val_loss: 1.5330 - val_accuracy: 0.6120\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 75us/step - loss: 1.1605 - accuracy: 0.6486 - val_loss: 1.4511 - val_accuracy: 0.6220\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 73us/step - loss: 1.0898 - accuracy: 0.6621 - val_loss: 1.4237 - val_accuracy: 0.6480\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 74us/step - loss: 1.0233 - accuracy: 0.6984 - val_loss: 1.4142 - val_accuracy: 0.6560\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 0.9643 - accuracy: 0.7225 - val_loss: 1.3778 - val_accuracy: 0.6730\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.9108 - accuracy: 0.7526 - val_loss: 1.3687 - val_accuracy: 0.6860\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.8629 - accuracy: 0.7674 - val_loss: 1.3661 - val_accuracy: 0.6910\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.8200 - accuracy: 0.7731 - val_loss: 1.3521 - val_accuracy: 0.7050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.7793 - accuracy: 0.7856 - val_loss: 1.3566 - val_accuracy: 0.7010\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.7456 - accuracy: 0.7907 - val_loss: 1.3483 - val_accuracy: 0.7020\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.7133 - accuracy: 0.7948 - val_loss: 1.3622 - val_accuracy: 0.7080\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 74us/step - loss: 0.6818 - accuracy: 0.7977 - val_loss: 1.3702 - val_accuracy: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe2ec1ff710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4761854196804927, 0.6896705031394958]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the information bottleneck in the second layer, the performance deteriorates from ~78% in the original model to ~69% here.\n",
    "\n",
    "### 4.2.2. Number of Layers\n",
    "\n",
    "We shall try between 1 and 3 hidden layers.  In all cases, we shall train on the optimum number of epochs (according to the validated loss) and use 64 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[# Layers: 1, Optimum Epochs: 10, Validation Loss: 0.8197776393890381, Validation Accuracy: 0.8209999799728394]\n",
      "[# Layers: 2, Optimum Epochs: 7, Validation Loss: 0.8643952832221985, Validation Accuracy: 0.8190000057220459]\n",
      "[# Layers: 3, Optimum Epochs: 8, Validation Loss: 0.9922438554763794, Validation Accuracy: 0.7960000038146973]\n"
     ]
    }
   ],
   "source": [
    "nLayers = np.arange(1, 4, 1)\n",
    "\n",
    "loss_values = np.zeros(len(nLayers))\n",
    "val_loss_values = np.zeros(len(nLayers))\n",
    "acc_values = np.zeros(len(nLayers))\n",
    "val_acc_values = np.zeros(len(nLayers))\n",
    "for i, n in enumerate(nLayers):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "    if n > 1:\n",
    "        for i in range(n - 1):\n",
    "            model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    h = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, \n",
    "                  validation_data=(x_val, y_val), verbose=0)\n",
    "    h = h.history\n",
    "    \n",
    "    minInd = np.argmin(h['val_loss'])\n",
    "    \n",
    "    loss_values[i] = h['loss'][minInd]\n",
    "    val_loss_values[i] = h['val_loss'][minInd]\n",
    "    acc_values[i] = h['accuracy'][minInd]\n",
    "    val_acc_values[i] = h['val_accuracy'][minInd]\n",
    "    \n",
    "    print(\"[# Layers: %s, Optimum Epochs: %s, Validation Loss: %s, Validation Accuracy: %s]\"\n",
    "          %(n, minInd + 1, val_loss_values[i], val_acc_values[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that having two hidden layers is indeed optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
